---
title: "在R Markdown文档中使用中文"
author: "童鑫"
documentclass: ctexart
geometry: "left=2.5cm,right=2cm,top=3cm,bottom=2.5cm"
output: 
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  error = FALSE,
  out.width = "100%", 
  fig.showtext = TRUE,
  fig.align = "center",
  comment = "#>",
  df_print = "tibble",
  paged.print = FALSE,
  split = FALSE
)

library(showtext)

showtext_auto()

# 添加微软雅黑字体
font_add("Microsoft YaHei", "C:/Windows/Fonts/msyh.ttc")

```


# 引言

中文LaTeX文档并非难题。当然这句话得站在巨人 [CTeX](http://ctex.org) 的肩膀上才能说，它让我们只需要一句

```latex
\documentclass{ctexart} % 或者ctexrep/ctexbook
```

或者

```latex
\usepackage{ctex}
```

就轻松搞定中文LaTeX排版问题。

# 字体和选项

LaTeX包[**ctex**](http://ctan.org/pkg/ctex)支持若干种字体选项，如果你是**ctex**老用户，请注意这里我们要求的最低版本是2.2，你可能需要升级你的LaTeX包。从版本2.0开始，**ctex**支持根据不同操作系统自动选择中文字体，简直是为人类进步作出了巨大贡献，我们再也不必费尽口舌向用户解释“啊，你用Windows啊，那么你该使用什么字体；啊，你用Mac啊，又该如何如何”。

下面的YAML元数据应该能满足多数用户的需求，主要设置两项参数：文档类为`ctexart`（当然也可以是别的类），输出格式为`rticles::ctex`，其默认LaTeX引擎为XeLaTeX（真的，别纠结你的旧爱PDFLaTeX了）。

```yaml
---
documentclass: ctexart
output: rticles::ctex
---
```

`rticles::ctex`的参数都是普通的`pdf_document`参数，参见文档**rmarkdown**包的文档，这里就不赘述了。

Windows和Mac用户应该都已经有自带的中文字体了。Linux用户可以考虑 [Fandol字体](http://ctan.org/pkg/fandol)，它号称是免费的，不过我们也没太搞清楚它的来头。如果你不想操心这些问题，我们强烈建议你卸载你当前的 LaTeX 套装（TeX Live 或 MiKTeX 或 MacTeX），换上 TinyTeX，一切将会自动化搞定。

```{r eval=FALSE}
devtools::install_github(c('rstudio/rmarkdown', 'yihui/tinytex'))
tinytex::install_tinytex()
#问题1.1:

```{r}
#问题1.1: BigBangTheory. (Attached Data: BigBangTheory)
bigbang <- read.csv("data/BigBangTheory.csv")
# 计算观众数量的最小值和最大值，计算均值、中位数和众数，计算第一和第三四分位数
min_viewers <- min(bigbang$Viewers..millions., na.rm = TRUE)
max_viewers <- max(bigbang$Viewers..millions., na.rm = TRUE)
mean_viewers <- mean(bigbang$Viewers..millions., na.rm = TRUE)
median_viewers <- median(bigbang$Viewers..millions., na.rm = TRUE)
mode_viewers <- modeest::mfv(bigbang$Viewers..millions., na.rm = TRUE)
first_quartile <- quantile(bigbang$Viewers..millions., 0.25, na.rm = TRUE)
third_quartile <- quantile(bigbang$Viewers..millions., 0.75, na.rm = TRUE)
# 查看分析结果
result1 <- data.frame(最小值 = min_viewers, 最大值 = max_viewers, 均值 = mean_viewers, 中位数 = median_viewers, 第一四分位数 = first_quartile, 第三四分位数 = third_quartile)
result2 <- data.frame(众数 = mode_viewers)
result1
result2
```

#问题1.2

```{r}
#问题1.2::has viewership grown or declined over the 2011–2012 season? Discuss.
library(tidyverse)
library(lubridate)
  
# 读取数据
df <- read.csv("data/BigBangTheory.csv", stringsAsFactors = FALSE, fileEncoding = "UTF-8")

# 将Air.Date列转换为日期格式
df$Air.Date <- mdy(df$Air.Date)

# 提取年份和季度作为标识
df$Year <- year(df$Air.Date)
df$Quarter <- quarter(df$Air.Date)

# 筛选出2011到2012年的数据
df_subset <- df %>% filter(Year >= 2011 & Year <= 2012)

# 按照年份和季度分组，并计算平均收视率
quarterly_data <- df_subset %>% 
  group_by(Year, Quarter) %>% 
  summarise(ave_viewer = mean(Viewers..millions.),.groups = "drop") %>% 
  mutate(Quarter_Label = paste(Year, "Q", Quarter, sep = ""))

print(quarterly_data)

# 设置中文显示
Sys.setlocale("LC_ALL", "Chinese")

# 使用ggplot2绘制图表
ggplot(quarterly_data, aes(x = Quarter_Label, y = ave_viewer, group = 1)) +
    geom_line(color = "red") +
    labs(title = "2011年至2012年期间季度平均收视率的折线图",
         x = "季度",
         y = "平均收视率") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank())
  
```

#问题2：: NBAPlayerPts. (Attached Data: NBAPlayerPts)

```{r}
#加载文件
nba_score <- read.csv("data/NBAPlayerPts.csv")
# 问题2.1

# a. 显示频率分布
hist(nba_score$PPG, breaks = seq(10, 30, by = 5), xlab = '平均得分数(PPG)', main = '频率分布直方图', col = 'blue')

# 查看并打印结果
hist_df <- hist(nba_score$PPG, breaks = seq(10, 30, by = 5),
                plot = FALSE)$counts
print('频率分布')
print(hist_df)

# b. 显示相对频率分布
hist_freq <- hist(nba_score$PPG, breaks = seq(10, 30, by = 5),
                  plot = FALSE)
hist_freq$density <- hist_freq$counts / sum(hist_freq$counts) * 4

# 查看并打印结果
print('相对频率分布')
print(round(hist_freq$density, 2))

# 绘制相对频率分布直方图
plot(hist_freq, freq = FALSE, xlab = '平均得分数(PPG)',
     main = '相对频率分布', col = 'green')

# 添加相对频率数据标签
text(hist_freq$mids, hist_freq$density, labels = round(hist_freq$density, 2),
     pos = 3)

# c. 显示累积百分比频率分布
hist_cum <- hist(nba_score$PPG, breaks = seq(10, 30, by = 5),
                 plot = FALSE)
hist_cum$counts <- hist_cum$counts / sum(hist_cum$counts)

# 求累计比例
hist_cum$accumulative_count <- cumsum(hist_cum$counts)

# 将小数转换为百分比并查看结果
print('累积百分比频率分布')
print(round(hist_cum$accumulative_count * 100, 2))

# d. 展示平均得分数直方图
hist(nba_score$PPG, breaks = seq(10, 30, by = 5),
     xlab = '平均得分数(PPG)', main = '平均得分数直方图', col = 'red')

# e. 以直方图颜色深浅为判断依据，推测数据为右偏态分布，且25-30小组数据聚集

# f. 计算并打印平均得分至少20分的比例结果（频率保留两位小数）
pp_value <- length(nba_score$PPG[nba_score$PPG >= 20]) / length(nba_score$PPG)

# 查看并打印数据偏斜情况及比例结果
result_list <- list(
    "数据偏斜情况" = "右偏态分布",
    "平均得分至少20分的比例" = round(pp_value, 2)
)
print(result_list)
```

#问题3:一名研究人员报告调查结果，指出平均值的标准误差为20。总体标准差为500。

```{r}
#a.调查样本有多少
#已知平均误差和标准差
simga <- 500
SE <- 20
#根据公式计算样本n
n <- (simga/SE)^2
#输出样本n
print(paste("样本量为：",n))
#b.计算人口在 ±25 内的概率
#转化成标准正态分布
standard <- simga/sqrt(n)
z_low <- (-25)/standard
z_upr <- 25/standard
#使用pnorm函数计算数值
probability <- pnorm(z_upr)-pnorm(z_low)
#结果百分比转换
probability_percentage <- round(probability*100,1)
#输出结果
print(paste("人口在±25内概率为:",probability_percentage,"%"))
```

#问题4：青年专业杂志
```{r}
#导入数据
professional <- read.csv('data/Professional.csv')
#1. Develop appropriate descriptive statistics to summarize the data.
summary(professional)

#2.Develop 95% confidence intervals for the mean age and household income of subscribers
# 计算年龄的平均值和置信区间
age_t <- t.test(professional$Age,conf.level = 0.95)$conf.int
#结果保留两位小数
print(paste("年龄95%的置信区间为: [", round(age_t[1], 2), ", ", round(age_t[2], 2), "]"))
#因原表格列名有$符号，程序无法识别，现在进行名称替换
names <- names(professional)
names[7] <- "Household.Income"
colnames(professional) <- names
#再计算家庭收入置信区间
income_t <- t.test(professional$Household.Income,conf.level = 0.95)$conf.int
print(paste("收入95%的置信区间为: [", round(income_t[1], 2), ", ", round(income_t[2], 2), "]"))

#3.. Develop 95% confidence intervals for the proportion of subscribers who have broadband
# access at home and the proportion of subscribers who have children
# 总用户数
total_users <- 410

# 有宽带接入的用户数
broadband_users <- sum(grepl("Yes", professional$Broadband.Access))

# 有孩子的用户数
children_users <- sum(grepl("Yes", professional$Have.Children))

# 计算有宽带接入的用户比例的95%置信区间
ci_broadband <- prop.test(x = broadband_users, n = total_users)

# 计算有孩子的用户比例的95%置信区间
ci_children <- prop.test(x = children_users, n = total_users)

# 打印结果
cat("95% Confidence Interval for Broadband Access:\n")
print(ci_broadband$conf.int)
cat("\n95% Confidence Interval for Having Children:\n")
print(ci_children$conf.int)

#4. Would Young Professional be a good advertising outlet for online brokers? Justify your
#conclusion with statistical data.
# 加载必要的库
library(dplyr)

# 数据清洗-删除缺失值
professionals <- na.omit(professional) 

# 定义年轻专业人士
young_professionals <- filter(professionals, Age < 35)

# 描述性统计分析
summary_stats <- young_professionals %>%
  summarise(
    Average_Investments = mean(Value.of.Investments, na.rm = TRUE),
    Average_Transactions = mean(Number.of.Transactions, na.rm = TRUE),
    Household_Income = mean(Household.Income, na.rm = TRUE)
  )

# 相关性分析
correlation <- cor(young_professionals$Value.of.Investments, young_professionals$Number.of.Transactions)

# 回归分析
model <- lm(Number.of.Transactions ~ Value.of.Investments + Household.Income, data = young_professionals)

# 显示结果
summary(model)
#结论:截距项（Intercept）：估计值为5.218e+00，对应的 t 值很大（11.221），且 p 值小于2e-16，说明截距项在统计上是显著的。
#投资金额变量（Value.of.Investments）：估计值为1.521e-05，t 值为1.539，p 值为0.125，说明在给定的显著性水平下（通常0.05为常用显著性水平），该变量对交易次数的影响不显著。
#家庭收入变量（Household.Income）：估计值为3.938e-06，t 值为0.885，p 值为0.377，同样表明该变量对交易次数的影响在常用显著性水平下也不显著。
#整体模型的拟合优度方面，多重 R 平方（Multiple R-squared）为0.008684，调整后的 R 平方（Adjusted R-squared）为0.00313，数值都比较低，说明模型对数据的拟合程度较差，自变量对因变量的解释能力有限。
#F 统计量为1.564，对应的 p 值为0.2108，进一步表明整个模型在统计上并不显著，即所选取的自变量（投资金额和家庭收入）整体上对交易次数的影响不具有显著的线性关系。

#5.Would this magazine be a good place to advertise for companies selling educational software and computer games for young children?
# 加载ggplot2包
library(ggplot2)

# 确保数据框中的“是否有孩子”列是因子类型，以便于ggplot识别
professional$Have.Children <- as.factor(professional$Have.Children)

# 绘制箱线图，比较有孩子家庭和所有家庭的家庭收入
ggplot(professional, aes(x = Have.Children, y = Household.Income)) +
  geom_boxplot() +
  labs(title = "Boxplot of Household Income by Presence of Children",
       x = "Presence of Children",
       y = "Household Income") +
  theme_minimal()
#结论:通过箱线图可以看出有孩子和没孩子家庭House.income水平差别不大。并不适合做儿童类广告。

#6. Comment on the types of articles you believe would be of interest to readers of Young
#Professional

```

#问题5:
```{r}
#1.Conduct a hypothesis test for each sample at the .01 level of significance and determine what
#action, if any, should be taken. Provide the p-value for each test.
#导入数据
quality_data <- read.csv("data/Quality.csv")
# 定义显著性水平
alpha <- 0.01

# 计算样本均值和标准差
sample_means <- apply(quality_data, 1, mean)
sample_sds <- apply(quality_data, 1, sd)

# 总体标准差
sigma <- 0.21
n <- 30

# 进行假设检验
t_tests <- sapply(1:nrow(quality_data), function(i) {
  t_stat <- (sample_means[i] - 12) / (sigma / sqrt(n))
  p_value <- 2 * pt(abs(t_stat), df = n - 1, lower.tail = FALSE)
  list(t_stat = t_stat, p_value = p_value)
})

# 输出结果
t_tests

#2 算每个样本的标准差
sample_sds

# 判断假设是否合理
mean(sample_sds)  # 计算样本标准差的平均值

#3
# 计算控制限
upper_limit <- 12 + 3 * (sigma / sqrt(n))
lower_limit <- 12 - 3 * (sigma / sqrt(n))

# 输出控制限
c(upper_limit, lower_limit)

#4.discuss the implications of changing the level of significance to a larger value. what mistake
#r error could increase if the level of significance is increased?
# 如果显著性水平增加，第一类错误（错误地拒绝正确的零假设）的风险会增加。
# 这意味着可能会更频繁地采取不必要的纠正措施，导致成本增加和生产效率降低。
```


#问题6：
```{r}
#导入数据
data <- read.csv("data/Occupancy.csv")
#1.Estimate the proportion of units rented during the first week of March 2007 and the first week
#of March 2008
#将原始数据转化为0/1，区分是否出租
data$Mar.07 <- ifelse(data$Mar.07=="Yes",1,0)
data$Mar.08 <- ifelse(data$Mar.08=="Yes",1,0)
#计算样本大小
n <- nrow(data)
# 计算2007年3月第一周出租单位的比例
prop_2007 <- mean(data$Mar.07)  # 假设CSV文件中的列名是"March 2007"

# 计算2008年3月第一周出租单位的比例
prop_2008 <- mean(data$Mar.08)  # 假设CSV文件中的列名是"March 2008"

# 打印结果
cat("Proportion of units rented in Mar.07:", prop_2007, "\n")
cat("Proportion of units rented in Mar.08:", prop_2008, "\n")
#2.Provide a 95% confidence interval for the difference in proportions.
# 计算比例差异的标准误差
se_diff <- sqrt((prop_2007 * (1 - prop_2007) / n) + (prop_2008 * (1 - prop_2008) / n))

# 计算95%置信区间
ci_diff <- c(prop_2008 - prop_2007 - 1.96 * se_diff, prop_2008 - prop_2007 + 1.96 * se_diff)

# 打印结果
cat("95% Confidence Interval for the difference in proportions:", ci_diff, "\n")

#3.. On the basis of your findings, does it appear March rental rates for 2008 will be up
#from those a year earlier?
# 判断置信区间是否完全大于0
if (ci_diff[1] > 0) {
  cat("表明08年3月租金会同比上升.\n")
} else {
  cat("没有明显证据证明08年3月租金会同比上升.\n")
}
```

#问题7:Question #7: Air Force Training Program
```{r}
#导入数据
train <- read.csv("data/Training.csv")

#1.. use appropriate descriptive statistics to summarize the training time data for each method.
#what similarities or differences do you observe from the sample data?
# 描述性统计
summary_current <- summary(train$Current)
summary_proposed <- summary(train$Proposed)
# 打印结果
cat("当前方法的描述性统计:\n")
print(summary_current)
cat("提议方法的描述性统计:\n")
print(summary_proposed)
#2.Comment on any difference between the population means for the two methods. Discuss
# your findings.
# t检验
t_test_result <- t.test(train$Current, train$Proposed, var.equal = TRUE)
print(t_test_result)

#3.c. compute the standard deviation and variance for each training method. conduct a hypothesis
#test about the equality of population variances for the two training methods. Discuss your
#findings
# 计算标准差和方差
sd_current <- sd(train$Current)
var_current <- var(train$Current)
sd_proposed <- sd(train$Proposed)
var_proposed <- var(train$Proposed)

# 方差齐性检验
var_test_result <- var.test(train$Current, train$Proposed)
print(var_test_result)

#4. what conclusion can you reach about any differences between the two methods? what is your
#recommendation? explain
#结论：两种方法的均值没有显著差异，但方差存在显著差异，表明提议方法在训练时间上更加一致。
#5.can you suggest other data or testing that might be desirable before making a final decision
#on the training program to be used in the future?
#鉴于两种方法的均值相似，但提议方法的方差较小，可能更值得考虑采用提议方法，因为它可能提供更一致的训练体验。
```


#问题8:The Toyota Camry is one of the best-selling cars in North America.
```{r}
#加载数据
camry <- read.csv("data/Camry.csv")
#1.a. Develop a scatter diagram with the car mileage on the horizontal axis and the price on the
#vertical axis.
# 1.a. 绘制散点图
ggplot(camry, aes(x = camry$Miles, y = camry$Price)) +
  geom_point() +  # 添加散点图
  geom_smooth()  # 添加默认的平滑拟合线

#2.b. what does the scatter diagram developed in part (a) indicate about the relationship between
#the two variables?
#答：从散点图中，我们可以看出里程和价格之间存在负相关关系。随着里程的增加，价格呈下降趋势

#3.c. Develop the estimated regression equation that could be used to predict the price ($1000s)
#given the miles (1000s).
# 3.c. 估计回归方程
model <- lm(camry$Price ~ camry$Miles, data=camry)
summary(model)

#4.d. Test for a significant relationship at the .05 level of significance.
#答：从回归方程的估计结果中，我们可以看到Miles的p值为0.000348，远小于0.05，因此在0.05的显著性水平下，
#Miles对Price有显著的影响。

#5.e. Did the estimated regression equation provide a good fit? Explain.
#答：R平方值 0.5387，调整后的R平方值为0.5115，这表明回归方程对数据的拟合度较好，可以解释51.15%的价格变化。

#6.f. Provide an interpretation for the slope of the estimated regression equation.
#答：斜率-0.05877表示每增加1000英里的里程，价格平均下降0.05877千美元。

#7.g. Suppose that you are considering purchasing a previously owned 2007 Camry that has been
#driven 60,000 miles. Using the estimated regression equation developed in part (c), predict the
#price for this car. Is this the price you would offer the seller

# 获取模型的系数
coefficients <- coef(model)
intercept <- coefficients[1]
slope <- coefficients[2]

# 计算预测价格
predicted_price <- intercept + slope * 60
predicted_price
predicted_price_2 <- round(predicted_price, 2)
paste("预测价格$",predicted_price_2,"千元")
```


#问题9：附件WE.xlsx是某提供⽹站服务的Internet服务商的客户数据。数据包含了6347名客
  #户在11个指标上的表现。其中”流失“指标中0表示流失，”1“表示不流失，其他指标含义看变量命
  #名
```{r}
#0.导入数据
library(readxl)
data <- read_excel("data/WE.xlsx")
#1a. 通过可视化探索流失客户与⾮流失客户的⾏为特点（或特点对⽐），你能发现流失与⾮流失客
  #户⾏为在哪些指标有可能存在显著不同？
data_long <- data %>%
  pivot_longer(cols = -流失, names_to = "指标", values_to = "值") %>%
  mutate(流失 = factor(流失, labels = c("非流失", "流失")))

ggplot(data_long, aes(x = 流失, y = 值, fill = 流失)) +
  geom_boxplot() +
  facet_wrap(~指标, scales = "free") +
  labs(title = "流失与非流失客户行为特点比较", x = "客户状态", y = "指标值")

#2b. 通过均值⽐较的⽅式验证上述不同是否显著。
# 计算均值并进行t检验
t_tests <- data %>%
  pivot_longer(cols = -流失, names_to = "指标", values_to = "值") %>%
  group_by(指标) %>%
  do({
    t_test <- t.test(.$值[.$流失 == 0], .$值[.$流失 == 1])
    data.frame(指标 = unique(.$指标), 非流失_mean = mean(.$值[.$流失 == 0], na.rm = TRUE), 流失_mean = mean(.$值[.$流失 == 1], na.rm = TRUE), p_value = t_test$p.value)
  }) %>%
  ungroup()

# 显示t检验结果
t_tests
print(t_tests)

#3.c. 以”流失“为因变量，其他你认为重要的变量为⾃变量（提示：a、b两步的发现），建⽴回归⽅
  #程对是否流失进⾏预测。
model <- glm(流失 ~ 客户ID + 当月客户幸福指数 + 客户幸福指数相比上月变化 + 当月客户支持  + 当月服务优先级, data = data, family = binomial)

# 显示模型摘要
summary(model)

#4.d. 根据上⼀步预测的结果，对尚未流失（流失=0）的客户进⾏流失可能性排序，并给出流失可能
  #性最⼤的前100名⽤户ID列表。
# 筛选出尚未流失的客户
data_non_churn <- data[data$流失 == 0, ]

# 预测尚未流失的客户流失可能性
predictions <- predict(model, newdata = data_non_churn, type = "response")

# 将预测结果添加到筛选后的数据框中
data_non_churn$predictions <- predictions

# 对尚未流失的客户进行排序
data_non_churn_sorted <- data_non_churn[order(-data_non_churn$predictions), ]

# 显示流失可能性最大的前100名用户ID
top100_users <- head(data_non_churn_sorted$客户ID, 100)
print(top100_users)

```

